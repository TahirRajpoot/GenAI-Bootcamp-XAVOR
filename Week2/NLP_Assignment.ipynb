{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Gen-AI Bootcamp 24**\n",
    "## **Natural Language Processing Course Assignment**\n",
    "\n",
    "### **Task 1: Text Collection and Loading**\n",
    "\n",
    "\n",
    "**Domain Choosen:** Top Rated TV Shows\n",
    "\n",
    "**Datset Link:** https://www.kaggle.com/datasets/titassaha/top-rated-tv-shows\n",
    "\n",
    "\n",
    "### **Loading the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2617, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      first_air_date origin_country original_language               name  \\\n",
       "0        2021-09-03             US                en  The D'Amelio Show   \n",
       "1        2008-01-20             US                en       Breaking Bad   \n",
       "2        2021-11-06             US                en             Arcane   \n",
       "3        2013-12-02             US                en     Rick and Morty   \n",
       "4        2022-04-14             US                en    The Kardashians   \n",
       "...             ...            ...               ...                ...   \n",
       "2612     2002-06-11             US                en      American Idol   \n",
       "2613     2000-07-05             US                en        Big Brother   \n",
       "2614     1997-03-31             GB                en        Teletubbies   \n",
       "2615     1985-02-19             GB                en         EastEnders   \n",
       "2616     2006-10-09             CA                fr             La Job   \n",
       "\n",
       "      popularity  vote_average  vote_count  \\\n",
       "0         30.104           9.0        3071   \n",
       "1        468.253           8.8       10131   \n",
       "2         95.667           8.7        2615   \n",
       "3       1511.996           8.7        7220   \n",
       "4        195.038           8.7        1627   \n",
       "...          ...           ...         ...   \n",
       "2612      34.052           5.2         135   \n",
       "2613      47.029           4.9         190   \n",
       "2614      36.875           4.1         108   \n",
       "2615     108.720           3.9         183   \n",
       "2616       6.968           0.6         162   \n",
       "\n",
       "                                               overview  \n",
       "0     From relative obscurity and a seemingly normal...  \n",
       "1     When Walter White, a New Mexico chemistry teac...  \n",
       "2     Amid the stark discord of twin cities Piltover...  \n",
       "3     Rick is a mentally-unbalanced but scientifical...  \n",
       "4     The family you know and love is here with a br...  \n",
       "...                                                 ...  \n",
       "2612  Each year, hopeful singers from all over the c...  \n",
       "2613  American version of the reality game show whic...  \n",
       "2614  Pre-school fun, fantasy and education with col...  \n",
       "2615  The everyday lives of working-class residents ...  \n",
       "2616  La Job is a French Canadian comedy television ...  \n",
       "\n",
       "[2617 rows x 8 columns]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading datset of top rated TV Drama\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data_TV.csv\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Task 2: Text Preprocessing**\n",
    "**Objective:** Gain hands-on experience with text preprocessing techniques.\n",
    "\n",
    "\n",
    "Choose Gutenberg Corpus\n",
    "\n",
    "\n",
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Emma by Jane Austen 1816]\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died too long ago for her to have more than an indistinct\n",
      "remembrance of her caresses; and her place had been supplied\n",
      "by an excellent woman as governess, who had fallen little short\n",
      "of a mother in affection.\n",
      "\n",
      "Sixteen years had Miss Taylor been in Mr. Woodhouse's family,\n",
      "less as a governess than a friend, very fond of both daughters,\n",
      "but particularly of Emma.  Between _them_ it was more the intimacy\n",
      "of sisters.  Even before Miss Taylor had ceased to hold the nominal\n",
      "office of governess, the mildness o\n",
      "\n",
      "Sentences: ['[Emma by Jane Austen 1816]\\n\\nVOLUME I\\n\\nCHAPTER I\\n\\n\\nEmma Woodhouse, handsome, clever, and rich, with a comfortable home\\nand happy disposition, seemed to unite some of the best blessings\\nof existence; and had lived nearly twenty-one years in the world\\nwith very little to distress or vex her.\\n\\n', \"She was the youngest of the two daughters of a most affectionate,\\nindulgent father; and had, in consequence of her sister's marriage,\\nbeen mistress of his house from a very early period.  \", 'Her mother\\nhad died too long ago for her to have more than an indistinct\\nremembrance of her caresses; and her place had been supplied\\nby an excellent woman as governess, who had fallen little short\\nof a mother in affection.\\n\\n', \"Sixteen years had Miss Taylor been in Mr. Woodhouse's family,\\nless as a governess than a friend, very fond of both daughters,\\nbut particularly of Emma.  \", 'Between _them_', 'it was more the intimacy\\nof sisters.  ', \"Even before Miss Taylor had ceased to hold the nominal\\noffice of governess, the mildness of her temper had hardly allowed\\nher to impose any restraint; and the shadow of authority being\\nnow long passed away, they had been living together as friend and\\nfriend very mutually attached, and Emma doing just what she liked;\\nhighly esteeming Miss Taylor's judgment, but directed chiefly by\\nher own.\\n\\n\", \"The real evils, indeed, of Emma's situation were the power of having\\nrather too much her own way, and a disposition to think a little\\ntoo well of herself; these were the disadvantages which threatened\\nalloy to her many enjoyments.  \", 'The danger, however, was at present\\nso unperceived, that they did not by any means rank as misfortunes\\nwith her.\\n\\n', 'Sorrow came--a gentle sorrow--but not at all in the shape of any\\ndisagreeable consciousness.--Miss Taylor married.  ']\n",
      "\n",
      "Words: ['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', '\\n\\n', 'VOLUME', 'I', '\\n\\n', 'CHAPTER', 'I', '\\n\\n\\n', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', '\\n', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', '\\n', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty', '-', 'one', 'years', 'in', 'the', 'world', '\\n', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.', '\\n\\n', 'She', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', '\\n', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', ',', '\\n', 'been', 'mistress', 'of', 'his']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "# Load SpaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load the text from the Gutenberg corpus\n",
    "gutenberg_text = gutenberg.raw('austen-emma.txt')\n",
    "print(gutenberg_text[:1000])  # Print the first 1000 characters for brevity\n",
    "\n",
    "# Process the text with SpaCy\n",
    "doc = nlp(gutenberg_text)\n",
    "\n",
    "# Split the text into sentences\n",
    "sentences = list(doc.sents)\n",
    "print(\"\\nSentences:\", [sentence.text for sentence in sentences[:10]])  # Print the first 10 sentences for brevity\n",
    "\n",
    "# Split the text into words\n",
    "words = [token.text for token in doc]\n",
    "print(\"\\nWords:\", words[:100])  # Print the first 100 words for brevity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tokens: ['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', '\\n\\n', 'VOLUME', 'I', '\\n\\n', 'CHAPTER', 'I', '\\n\\n\\n', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', '\\n', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', '\\n', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty', '-', 'one', 'years', 'in', 'the', 'world', '\\n', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.', '\\n\\n', 'She', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', '\\n', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', ',', '\\n', 'been', 'mistress', 'of', 'his']\n",
      "\n",
      "Stemmed Tokens: ['[', 'emma', 'by', 'jane', 'austen', '1816', ']', '\\n\\n', 'volum', 'i', '\\n\\n', 'chapter', 'i', '\\n\\n\\n', 'emma', 'woodhous', ',', 'handsom', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfort', 'home', '\\n', 'and', 'happi', 'disposit', ',', 'seem', 'to', 'unit', 'some', 'of', 'the', 'best', 'bless', '\\n', 'of', 'exist', ';', 'and', 'had', 'live', 'nearli', 'twenti', '-', 'one', 'year', 'in', 'the', 'world', '\\n', 'with', 'veri', 'littl', 'to', 'distress', 'or', 'vex', 'her', '.', '\\n\\n', 'she', 'wa', 'the', 'youngest', 'of', 'the', 'two', 'daughter', 'of', 'a', 'most', 'affection', ',', '\\n', 'indulg', 'father', ';', 'and', 'had', ',', 'in', 'consequ', 'of', 'her', 'sister', \"'s\", 'marriag', ',', '\\n', 'been', 'mistress', 'of', 'hi']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "\n",
    "# Load SpaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load the text from the Gutenberg corpus\n",
    "gutenberg_text = gutenberg.raw('austen-emma.txt')\n",
    "\n",
    "# Process the text with SpaCy\n",
    "doc = nlp(gutenberg_text) # Using only the first 5000 characters for brevity\n",
    "\n",
    "# Tokenize the text into words (using SpaCy and list comprehension for better efficiency)\n",
    "tokens = [token.text for token in doc]\n",
    "\n",
    "# Initialize the Porter Stemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Apply stemming to each word\n",
    "stemmed_tokens = [porter_stemmer.stem(word) for word in tokens]\n",
    "\n",
    "# Print the first 100 tokens and the first 100 stemmed tokens for comparison\n",
    "print(\"Original Tokens:\", tokens[:100])\n",
    "print(\"\\nStemmed Tokens:\", stemmed_tokens[:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stemmed Tokens: ['[', 'emma', 'by', 'jane', 'austen', '1816', ']', '\\n\\n', 'volum', 'i', '\\n\\n', 'chapter', 'i', '\\n\\n\\n', 'emma', 'woodhous', ',', 'handsom', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfort', 'home', '\\n', 'and', 'happi', 'disposit', ',', 'seem', 'to', 'unit', 'some', 'of', 'the', 'best', 'bless', '\\n', 'of', 'exist', ';', 'and', 'had', 'live', 'nearli', 'twenti', '-', 'one', 'year', 'in', 'the', 'world', '\\n', 'with', 'veri', 'littl', 'to', 'distress', 'or', 'vex', 'her', '.', '\\n\\n', 'she', 'wa', 'the', 'youngest', 'of', 'the', 'two', 'daughter', 'of', 'a', 'most', 'affection', ',', '\\n', 'indulg', 'father', ';', 'and', 'had', ',', 'in', 'consequ', 'of', 'her', 'sister', \"'s\", 'marriag', ',', '\\n', 'been', 'mistress', 'of', 'hi']\n",
      "\n",
      "Lemmatized Tokens: ['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', '\\n\\n', 'volume', 'I', '\\n\\n', 'chapter', 'I', '\\n\\n\\n', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', '\\n', 'and', 'happy', 'disposition', ',', 'seem', 'to', 'unite', 'some', 'of', 'the', 'good', 'blessing', '\\n', 'of', 'existence', ';', 'and', 'have', 'live', 'nearly', 'twenty', '-', 'one', 'year', 'in', 'the', 'world', '\\n', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'she', '.', '\\n\\n', 'she', 'be', 'the', 'young', 'of', 'the', 'two', 'daughter', 'of', 'a', 'most', 'affectionate', ',', '\\n', 'indulgent', 'father', ';', 'and', 'have', ',', 'in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', ',', '\\n', 'be', 'mistress', 'of', 'his']\n"
     ]
    }
   ],
   "source": [
    "# Apply lemmatization to each word using SpaCy\n",
    "lemmatized_tokens = [token.lemma_ for token in doc]\n",
    "print(\"\\nStemmed Tokens:\", stemmed_tokens[:100])\n",
    "print(\"\\nLemmatized Tokens:\", lemmatized_tokens[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Stop Word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tokens: ['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', '\\n\\n', 'VOLUME', 'I', '\\n\\n', 'CHAPTER', 'I', '\\n\\n\\n', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', '\\n', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', '\\n', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty', '-', 'one', 'years', 'in', 'the', 'world', '\\n', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.', '\\n\\n', 'She', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', '\\n', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', ',', '\\n', 'been', 'mistress', 'of', 'his']\n",
      "\n",
      "Lemmatized Tokens: ['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', '\\n\\n', 'volume', 'I', '\\n\\n', 'chapter', 'I', '\\n\\n\\n', 'Emma', 'Woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', '\\n', 'and', 'happy', 'disposition', ',', 'seem', 'to', 'unite', 'some', 'of', 'the', 'good', 'blessing', '\\n', 'of', 'existence', ';', 'and', 'have', 'live', 'nearly', 'twenty', '-', 'one', 'year', 'in', 'the', 'world', '\\n', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'she', '.', '\\n\\n', 'she', 'be', 'the', 'young', 'of', 'the', 'two', 'daughter', 'of', 'a', 'most', 'affectionate', ',', '\\n', 'indulgent', 'father', ';', 'and', 'have', ',', 'in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', ',', '\\n', 'be', 'mistress', 'of', 'his']\n",
      "\n",
      "Filtered Tokens (Stop Words Removed): ['Emma', 'Jane', 'Austen', 'volume', 'chapter', 'Emma', 'Woodhouse', 'handsome', 'clever', 'rich', 'comfortable', 'home', 'happy', 'disposition', 'unite', 'good', 'blessing', 'existence', 'live', 'nearly', 'year', 'world', 'little', 'distress', 'vex', 'young', 'daughter', 'affectionate', 'indulgent', 'father', 'consequence', 'sister', 'marriage', 'mistress', 'house', 'early', 'period', 'mother', 'die', 'long', 'ago', 'indistinct', 'remembrance', 'caress', 'place', 'supply', 'excellent', 'woman', 'governess', 'fall', 'little', 'short', 'mother', 'affection', 'sixteen', 'year', 'Miss', 'Taylor', 'Woodhouse', 'family', 'governess', 'friend', 'fond', 'daughter', 'particularly', 'Emma', 'intimacy', 'sister', 'Miss', 'Taylor', 'cease', 'hold', 'nominal', 'office', 'governess', 'mildness', 'temper', 'hardly', 'allow', 'impose', 'restraint', 'shadow', 'authority', 'long', 'pass', 'away', 'live', 'friend', 'friend', 'mutually', 'attach', 'Emma', 'like', 'highly', 'esteem', 'Miss', 'Taylor', 'judgment', 'direct', 'chiefly']\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "filtered_tokens = [token for token in lemmatized_tokens if token.lower() not in stop_words and token.isalpha()]\n",
    "# Remove stop words\n",
    "print(\"Original Tokens:\", tokens[:100])\n",
    "print(\"\\nLemmatized Tokens:\", lemmatized_tokens[:100])\n",
    "print(\"\\nFiltered Tokens (Stop Words Removed):\", filtered_tokens[:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
